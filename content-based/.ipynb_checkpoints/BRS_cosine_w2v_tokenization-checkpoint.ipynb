{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89bfe4e8-23e1-49d1-aead-245ad9891b7c",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bfa463a-2bd7-4825-be9c-0ce60115a906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69fb480-3d9c-4988-a141-8e0e6df10e96",
   "metadata": {},
   "source": [
    "Data preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2992f4db-940e-4687-ad55-f049ae73bf9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2332, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_df = pd.read_csv(\"../datasets/clean/filtered_datasets/Final/final_books.csv\")\n",
    "book_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89f17e5-119c-48aa-b39d-3f88dce2602b",
   "metadata": {},
   "source": [
    "---\n",
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fd8a46-7c4f-4090-9740-b0636475b135",
   "metadata": {},
   "source": [
    "We have to preprocess the data for the word tokening approach.\n",
    "\n",
    "We will do the following techniques:\n",
    "1. Edit empty descriptions, remove special characters and remove stop words\n",
    "2. Tokenize the sentences\n",
    "3. Update the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c3d4fe8-99c6-4371-b3af-bc477a1df896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizing word embeddings to get better results\n",
    "import re\n",
    "# use nltk for the utilities in preprocessing\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#use gensim for the w2v and d2v\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#Make empty cells into empty strings (should not be a lot of them)\n",
    "# book_df['description'] = book_df['description'].fillna(' ') -> NO MORE CUZ WE REMOVED THEM\n",
    "\n",
    "# Convert 'description' column to string type\n",
    "book_df['description'] = book_df['description'].astype(str)\n",
    "\n",
    "for index, sentence in enumerate(book_df[\"description\"]):\n",
    "    # 1. Remove all special characters\n",
    "    preprocessed_sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence)\n",
    "    # 2. Tokenize the sentence\n",
    "    tokens = simple_preprocess(preprocessed_sentence)\n",
    "    # 3. Remove stop words\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # 4. Join tokens back into a sentence\n",
    "    processed_sentence = ' '.join(filtered_tokens)\n",
    "    # 5. Update the 'description' column with the processed sentence\n",
    "    book_df.at[index, 'description'] = processed_sentence\n",
    "\n",
    "\n",
    "# Tokenize the 'description' column\n",
    "book_df['tokenized_description'] = book_df['description'].apply(lambda x: x.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5111f9d6-6f42-49be-ba8f-14a5cfb56ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df.to_csv(\"./tokenized_book_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287918c6-c793-4598-918a-01f08ba232ca",
   "metadata": {},
   "source": [
    "### The tokenized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12a74bcc-fcf7-4144-a9c8-923611990d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>categories</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Testament</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>suicidal billionaire burnt washington litigator woman forsaken technology work wilds brazil brought together astounding mystery testament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Icebound</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>secret arctic experiment turns frozen nightmare team scientists stranded drifting iceberg massive explosive charge battles elements survival discover one murderer reissue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Book-Title categories  \\\n",
       "0  The Testament    Fiction   \n",
       "1       Icebound    Fiction   \n",
       "\n",
       "                                                                                                                                                                  description  \n",
       "0                                   suicidal billionaire burnt washington litigator woman forsaken technology work wilds brazil brought together astounding mystery testament  \n",
       "1  secret arctic experiment turns frozen nightmare team scientists stranded drifting iceberg massive explosive charge battles elements survival discover one murderer reissue  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 200) # -> to see more from the description\n",
    "book_df[['Book-Title','categories','description']].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bb286b-c5a8-4dad-804d-002f71fb2c2e",
   "metadata": {},
   "source": [
    "---\n",
    "## Word2Vector setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf42c0a-7b4e-4861-a6e1-5bcfc08f4ef6",
   "metadata": {},
   "source": [
    "We will configure and train the word2vector algorithm on the tokenized descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fa54515-2460-47cb-b1cd-87e44bfa32f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(770738, 782650)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v = Word2Vec(sentences=book_df['tokenized_description'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "w2v.train(book_df['tokenized_description'], total_examples=len(book_df['tokenized_description']), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c66d4a4-94da-469b-97a3-ce869e7fa49c",
   "metadata": {},
   "source": [
    "These are the top 3 common words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d93b9ed1-2d68-420f-a726-6384a81f4b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "life one new\n"
     ]
    }
   ],
   "source": [
    "print(w2v.wv.index_to_key[0], w2v.wv.index_to_key[1], w2v.wv.index_to_key [2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50adc63-2503-4101-a868-00c955e05449",
   "metadata": {},
   "source": [
    "---\n",
    "## Get book recommendataions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25c365e-d81c-41fd-b279-ca59e0d6dd89",
   "metadata": {},
   "source": [
    "We create a funtion that gets the title of the book in question and:\n",
    "- gets it's description\n",
    "- uses our word2vector model and the cosine similarity function to find similar descriptions\n",
    "- returns the most similar books by desription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cf47319-619b-4223-addb-1f7373816182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress runtime warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "def get_similar_books_word2vec(title, amount=10, model=w2v, book_df=book_df):\n",
    "    # Get the description tokens of the target book\n",
    "    description_tokens = book_df.loc[book_df['Book-Title'] == title, 'tokenized_description'].iloc[0]\n",
    "    # comppute the avg vector of the TARGET book's description tokens\n",
    "    target_vector = np.mean([model.wv[token] for token in description_tokens if token in model.wv], axis=0).reshape(1, -1)\n",
    "\n",
    "    similarity_scores = {}\n",
    "    for index, row in book_df.iterrows():\n",
    "        if row['Book-Title'] != title:\n",
    "            # compute the avg vector of the CURRENT book's description tokens\n",
    "            book_vector = np.mean([model.wv[token] for token in row['tokenized_description'] if token in model.wv], axis=0).reshape(1, -1)\n",
    "\n",
    "            # we want to skip nan values\n",
    "            if np.isnan(target_vector).any() or np.isnan(book_vector).any():\n",
    "                continue\n",
    "            # get the cosine similarity\n",
    "            similarity_scores[index] = cosine_similarity(target_vector, book_vector)[0, 0]\n",
    "    \n",
    "    # sort the books by similarity score in descending order\n",
    "    sorted_indices = sorted(similarity_scores, key=similarity_scores.get, reverse=True)\n",
    "    \n",
    "    # Return the most similar books\n",
    "    return book_df.iloc[sorted_indices[:amount]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d10d6c-ff21-4826-9d7b-dd652cd62e49",
   "metadata": {},
   "source": [
    "#### Function to get formatted recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b22c1fa2-78e3-4fa9-bbb1-402155a903c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_recom(title):\n",
    "    book = book_df.loc[book_df['Book-Title'] == title].iloc[0]\n",
    "    print(book[\"Book-Title\"]  + \" - \"+ book[\"categories\"] +  \" - \" + book[\"description\"])\n",
    "\n",
    "    recommended_books = get_similar_books_word2vec(title,amount=5)\n",
    "    print()\n",
    "    return(recommended_books)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ee6b65-e967-48c0-a5ef-d0b8991e6a11",
   "metadata": {},
   "source": [
    "---\n",
    "## Testing the recommendation model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b061463-7b95-42bf-8638-0b945039da3b",
   "metadata": {},
   "source": [
    "__Let's test the recommendation model.__\n",
    "\n",
    "We made it so you can see both the original books and the recommended books' title, genre and description.\\\n",
    "This way we can look and compare them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec647aad-b8cf-40b2-ba25-4bcfc42cda2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', 500) # -> to see more from the description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0038661a-d7b2-499d-99b0-8c825bcc02b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Icebound - Fiction - secret arctic experiment turns frozen nightmare team scientists stranded drifting iceberg massive explosive charge battles elements survival discover one murderer reissue\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>categories</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Strangers</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>group seemingly unrelated people experiences sensations numbing terror fear groping way toward one another discover sinister shared secrets chilling climax changes lives forever reissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>Fluke : Or, I Know Why the Winged Whale Sings</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>humpback whales sing question marine behavioral biologist nate quinn crew poking charting recording photographing big wet gray marine mammals extraordinary day whale lifts tail air display cryptic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>One Thousand White Women : The Journals of May Dodd: A Novel</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>one thousand white women story may dodd colorful assembly pioneer women auspices government travel western prairies intermarry among cheyenne indians covert controversial brides indians program la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>Shards of a Broken Crown (Serpentwar Saga, Book 4)</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>demon enemy routed well winter icy grasp loosening world emerald queen vanquished army broken back bitter sea treachery recourse lackey declared lord defeated amassing still fearsome remnants ruth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2302</th>\n",
       "      <td>Boy Who Turned into a TV Set</td>\n",
       "      <td>Juvenile Fiction</td>\n",
       "      <td>although mother warns continues watch television much turn one ogden pettibone believe discovers clear color picture glowing stomach</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Book-Title  \\\n",
       "20                                                       Strangers   \n",
       "320                  Fluke : Or, I Know Why the Winged Whale Sings   \n",
       "165   One Thousand White Women : The Journals of May Dodd: A Novel   \n",
       "595             Shards of a Broken Crown (Serpentwar Saga, Book 4)   \n",
       "2302                                  Boy Who Turned into a TV Set   \n",
       "\n",
       "            categories  \\\n",
       "20             Fiction   \n",
       "320            Fiction   \n",
       "165            Fiction   \n",
       "595            Fiction   \n",
       "2302  Juvenile Fiction   \n",
       "\n",
       "                                                                                                                                                                                                  description  \n",
       "20                  group seemingly unrelated people experiences sensations numbing terror fear groping way toward one another discover sinister shared secrets chilling climax changes lives forever reissue  \n",
       "320   humpback whales sing question marine behavioral biologist nate quinn crew poking charting recording photographing big wet gray marine mammals extraordinary day whale lifts tail air display cryptic...  \n",
       "165   one thousand white women story may dodd colorful assembly pioneer women auspices government travel western prairies intermarry among cheyenne indians covert controversial brides indians program la...  \n",
       "595   demon enemy routed well winter icy grasp loosening world emerald queen vanquished army broken back bitter sea treachery recourse lackey declared lord defeated amassing still fearsome remnants ruth...  \n",
       "2302                                                                     although mother warns continues watch television much turn one ogden pettibone believe discovers clear color picture glowing stomach  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_book_recom(\"Icebound\")[[\"Book-Title\",\"categories\",\"description\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ddf7ea5-5e12-4d68-a634-1dff4de8490b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Midnight Voices - Fiction - caroline two children move new spouse apartment central park west son instinctive misgivings become horrifying reality young girl vanishes caroline daughter begins waste away\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>categories</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>Devil May Care</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>ellie young rich engaged love carefree days marriage new responsibility anything goes including house sitting eccentric aunt kate palatial estate burton virginia ellie feels right home nearly invi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2252</th>\n",
       "      <td>Pygmalion: A Romance in Five Acts (Penguin Classics)</td>\n",
       "      <td>Literary Criticism</td>\n",
       "      <td>professor higgins succeeds transforming unkempt london flower girl society belle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>Night Train to Memphis</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>assistant curator munich national museum vicky bliss expert egypt ph solving crimes intelligence agency offers luxury nile cruise help solve murder stop heist egyptian antiquities takes plunge vic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Four To Score (A Stephanie Plum Novel)</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>stephanie plum trenton new jersey favorite pistol packing condom carrying bounty hunter back trail revenge seeking waitress skipped bail help year old grandma mazur ex hooker lula transvestite mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>Lucy Sullivan Is Getting Married</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>happens psychic tells lucy getting married within year roommates panic going happen blissful existence eating take drinking much wine bringing men home never vacuuming lucy reassures friends far b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Book-Title  \\\n",
       "1648                                        Devil May Care   \n",
       "2252  Pygmalion: A Romance in Five Acts (Penguin Classics)   \n",
       "902                                 Night Train to Memphis   \n",
       "118                 Four To Score (A Stephanie Plum Novel)   \n",
       "318                       Lucy Sullivan Is Getting Married   \n",
       "\n",
       "              categories  \\\n",
       "1648             Fiction   \n",
       "2252  Literary Criticism   \n",
       "902              Fiction   \n",
       "118              Fiction   \n",
       "318              Fiction   \n",
       "\n",
       "                                                                                                                                                                                                  description  \n",
       "1648  ellie young rich engaged love carefree days marriage new responsibility anything goes including house sitting eccentric aunt kate palatial estate burton virginia ellie feels right home nearly invi...  \n",
       "2252                                                                                                                         professor higgins succeeds transforming unkempt london flower girl society belle  \n",
       "902   assistant curator munich national museum vicky bliss expert egypt ph solving crimes intelligence agency offers luxury nile cruise help solve murder stop heist egyptian antiquities takes plunge vic...  \n",
       "118   stephanie plum trenton new jersey favorite pistol packing condom carrying bounty hunter back trail revenge seeking waitress skipped bail help year old grandma mazur ex hooker lula transvestite mus...  \n",
       "318   happens psychic tells lucy getting married within year roommates panic going happen blissful existence eating take drinking much wine bringing men home never vacuuming lucy reassures friends far b...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_book_recom(\"Midnight Voices\")[[\"Book-Title\",\"categories\",\"description\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b944fc4-43e0-46fa-934a-5283aeecd3ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Lord of the Rings - Fiction - epic detailing great war ring struggle good evil middle earth tiny hobbits play key role\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>categories</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Cryptonomicon</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>extraordinary first volume promises epoch making masterpiece neal stephenson hacks secret histories nations private obsessions men decrypting dazzling virtuosity forces shaped century lawrence pri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>Mitla Pass</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>writer gideon zadok leaves glitter hollywood newly created state israel learns much love dangerous military operation covers war correspondent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>Demonic Males : Apes and the Origins of Human Violence</td>\n",
       "      <td>Nature</td>\n",
       "      <td>draws recent discoveries human evolution examine whether violence among men product primitive heritage searches solutions problems war rape murder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>Xenocide : Volume Three of the Ender Quartet (Ender)</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>war survival planet lusitania fought heart child named gloriously bright lusitania ender found world humans pequininos hive queen could live together three different intelligent species could find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>Jukebox Queen Of Malta: A Novel</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>jukebox queen malta exquisite enchanting novel love war set island perilously balanced real rocco raven intrepid auto mechanic turned corporal brooklyn arrived malta mediterranean island neolithic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Book-Title categories  \\\n",
       "84                                             Cryptonomicon    Fiction   \n",
       "1278                                              Mitla Pass    Fiction   \n",
       "1016  Demonic Males : Apes and the Origins of Human Violence     Nature   \n",
       "1454    Xenocide : Volume Three of the Ender Quartet (Ender)    Fiction   \n",
       "570                          Jukebox Queen Of Malta: A Novel    Fiction   \n",
       "\n",
       "                                                                                                                                                                                                  description  \n",
       "84    extraordinary first volume promises epoch making masterpiece neal stephenson hacks secret histories nations private obsessions men decrypting dazzling virtuosity forces shaped century lawrence pri...  \n",
       "1278                                                           writer gideon zadok leaves glitter hollywood newly created state israel learns much love dangerous military operation covers war correspondent  \n",
       "1016                                                       draws recent discoveries human evolution examine whether violence among men product primitive heritage searches solutions problems war rape murder  \n",
       "1454  war survival planet lusitania fought heart child named gloriously bright lusitania ender found world humans pequininos hive queen could live together three different intelligent species could find...  \n",
       "570   jukebox queen malta exquisite enchanting novel love war set island perilously balanced real rocco raven intrepid auto mechanic turned corporal brooklyn arrived malta mediterranean island neolithic...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_book_recom(\"The Lord of the Rings\")[[\"Book-Title\",\"categories\",\"description\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbbbff54-b3b8-4939-a001-0a2054df090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.save(\"Models/word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdf44a2-1270-4636-967f-37064f0db457",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
